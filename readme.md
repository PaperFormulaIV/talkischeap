# 工具箱的深度學習記事簿

## 這是什麼

這個倉庫包含了或即將包含深度學習相關從基礎知識和更高級一點的知識。每篇內容包含了你關注的兩個點：

- 這個知識有什麼用
- 這個知識如何實用

**請注意，本倉庫使用 [MX-Net](http://mxnet.apache.org/) 庫。**

---

## But why ?

> 理解深度学习的最佳方法是学以致用。

衆所周知，工具箱的深度學習基礎很爛，至少在 F4 裏是穩穩的墊底。通過看着教程敲出這個倉庫，也許工具箱能夠實現從最爛到不是很爛的蛻變。所使用的書記是[這本](https://github.com/d2l-ai/d2l-zh)

---

## 目錄

目錄的使用方法：點擊前面的標題進入相關頁面，點擊後面的代碼實現進入相關代碼實現。打了對勾的是已經寫了的，沒打的說明在寫了（咕咕咕），祝你旅途愉快。

### 第零章：預備知識

- [x] [使用 conda 創建一個環境](./ch0/create-new-environment-using-conda.md)
- [x] [配置GPU](./ch0/configure-gpu.md)
- [x] [數據操作](./ch0/operate-on-data.md)
- [x] [自動求梯度](./ch0/automatic-gradient.md)

### 第一章：深度學習基礎

- [ ] [線性回歸]() | [代碼實現]()
- [ ] [softmax 回歸]() | [代碼實現]()
- [ ] [多層感知機]() | [代碼實現]()
- [ ] [模型選擇，欠擬合和過擬合]()
- [ ] [權重衰減]()
- [ ] [丟棄法]()
- [ ] [正向傳播和反向傳播]()

### 第二章：深度學習計算

- [ ] [模型構造]()
- [ ] [模型參數的訪問、初始化和共享]()
- [ ] [模型參數的延後初始化]()
- [ ] [自定義層]()
- [ ] [讀取和存儲]()
- [ ] [使用 GPU 運算]()

### 第三章：卷積神經網絡

- [ ] [二維卷積層]()
- [ ] [填充和步幅]()
- [ ] [多輸入通道和多輸出通道]()
- [ ] [池化層]()
- [ ] [卷積神經網絡(LeNet)]()
- [ ] [深度卷積神經網絡(AlexNet)]()
- [ ] [使用重複元素的網絡(VGG)]()
- [ ] [網絡中的網絡(NiN)]()
- [ ] [含有並行連接的網絡]()
- [ ] [批量歸一化]()
- [ ] [殘差網絡(ResNet)]()
- [ ] [稠密連接網絡(DenseNet)]()

### 第四章：循環神經網絡

- [ ] [語言模型]()
- [ ] [循環神經網絡]() | [代碼實現]()
- [ ] [語言模型數據集(歌詞)]()
- [ ] [通過時間反向傳播]()
- [ ] [門控循環單元(GRU)]()
- [ ] [長短期記憶(LSTM)]()
- [ ] [深度循環神經網絡]()
- [ ] [雙向循環神經網絡]()

### 第五章：計算機視覺

- [ ] [圖像增廣]()
- [ ] [微調]()
- [ ] [目標檢測和邊界框]()
- [ ] [錨框]()
- [ ] [多尺度目標檢測]()
- [ ] [目標檢測數據集(皮卡丘)]()
- [ ] [單發多框檢測(SSD)]()
- [ ] [區域卷積神經網絡(R-CNN)系列]()
- [ ] [語義分割和數據集]()
- [ ] [全卷積網絡(FCN)]()
- [ ] [樣式遷移]()
- [ ] [實戰 Sifar-10]() | [實戰 ImageNet-Dogs]()

### 附錄

- [ ] [使用的符號]()
- [ ] [數學基礎]()
